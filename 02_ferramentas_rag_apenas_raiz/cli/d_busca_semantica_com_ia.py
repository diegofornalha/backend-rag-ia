#!/usr/bin/env python3
"""
Ferramenta CLI para realizar buscas sem√¢nticas com processamento LLM e interface conversacional.
"""

import os
import json
import requests
from typing import List, Dict, Optional
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.prompt import Prompt
from rich.spinner import Spinner
from rich.markdown import Markdown
from contextlib import contextmanager
from dotenv import load_dotenv
import google.generativeai as genai

# Carrega vari√°veis de ambiente
load_dotenv()

# Configura console
console = Console()

def get_api_url(endpoint: str = "") -> str:
    """
    Constr√≥i a URL da API.
    
    Args:
        endpoint: Endpoint da API (opcional)
        
    Returns:
        str: URL completa da API
    """
    base_url = os.getenv("ACTIVE_URL", os.getenv("LOCAL_URL", "http://localhost:10000"))
    api_version = os.getenv("API_VERSION", "v1")
    base = f"{base_url}/api/{api_version}"
    return f"{base}/{endpoint.lstrip('/')}" if endpoint else base

class GeminiChat:
    """Gerencia chat com Gemini."""
    
    def __init__(self):
        """Inicializa modelo Gemini em modo chat."""
        gemini_key = os.getenv("GEMINI_API_KEY")
        if not gemini_key:
            raise ValueError("GEMINI_API_KEY n√£o encontrada no .env")
            
        genai.configure(api_key=gemini_key)
        self.model = genai.GenerativeModel('gemini-pro')
        self.chat = self.model.start_chat(history=[])
        
        # Define o papel do assistente
        system_prompt = """Voc√™ √© um assistente amig√°vel e conversacional que ajuda usu√°rios a encontrar informa√ß√µes.
        
        Seu objetivo √© primeiro entender claramente o que o usu√°rio precisa antes de buscar informa√ß√µes.
        
        Diretrizes:
        1. Seja amig√°vel e conversacional
        2. Se a pergunta for vaga ou gen√©rica, fa√ßa perguntas para clarificar
        3. Quando entender bem a necessidade, use [BUSCAR] para indicar que est√° pronto para pesquisar
        4. Ap√≥s receber documentos, baseie suas respostas apenas neles
        5. Use markdown para formatar respostas
        
        Exemplos:
        Usu√°rio: "oi"
        Voc√™: "Ol√°! Como posso ajudar voc√™ hoje?"
        
        Usu√°rio: "me fala sobre as regras"
        Voc√™: "Claro! Mas para ajudar melhor, voc√™ gostaria de saber sobre quais regras espec√≠ficas? Por exemplo:
        ‚Ä¢ Regras de desenvolvimento
        ‚Ä¢ Regras de documenta√ß√£o
        ‚Ä¢ Regras de organiza√ß√£o
        ‚Ä¢ Ou outro tipo espec√≠fico?"
        
        Usu√°rio: "quero saber sobre as regras de documenta√ß√£o"
        Voc√™: "[BUSCAR] Vou pesquisar informa√ß√µes sobre as regras de documenta√ß√£o do projeto."
        """
        
        self.chat.send_message(system_prompt, stream=False)
        
    def should_search(self, response: str) -> bool:
        """Verifica se a resposta indica que deve realizar busca."""
        return "[BUSCAR]" in response
        
    def process_initial_response(self, query: str) -> str:
        """Processa query inicial do usu√°rio para entender a inten√ß√£o.
        
        Args:
            query: Pergunta do usu√°rio
            
        Returns:
            Resposta inicial ou indica√ß√£o para busca
        """
        try:
            response = self.chat.send_message(query, stream=False)
            if response and hasattr(response, 'text'):
                return response.text
            return "Desculpe, n√£o consegui processar sua mensagem. Pode reformular?"
        except Exception as e:
            console.print(f"\n[red]Erro ao processar com Gemini: {str(e)}[/red]")
            return "Desculpe, ocorreu um erro ao processar sua mensagem."
    
    def process_search_response(self, query: str, documents: List[Dict]) -> str:
        """Processa resposta ap√≥s busca nos documentos.
        
        Args:
            query: Pergunta do usu√°rio
            documents: Lista de documentos relevantes
            
        Returns:
            Resposta processada
        """
        try:
            # Prepara contexto com documentos
            context = "Documentos relevantes encontrados:\n\n"
            
            # Garante que documents √© uma lista
            if not isinstance(documents, list):
                documents = []
            
            for doc in documents:
                # Extrai conte√∫do com tratamento de erro
                try:
                    content = doc.get("conteudo", {})
                    if isinstance(content, str):
                        try:
                            content = json.loads(content)
                        except:
                            content = {"text": content}
                    
                    text = content.get("text", "").strip()
                    if text:
                        # Limita tamanho do texto para evitar exceder limites do Gemini
                        if len(text) > 1000:
                            text = text[:1000] + "..."
                        context += f"---\n{text}\n"
                except Exception as e:
                    console.print(f"\n[yellow]Aviso ao processar documento: {str(e)}[/yellow]")
                    continue
            
            # Se n√£o houver documentos v√°lidos
            if context == "Documentos relevantes encontrados:\n\n":
                context = "N√£o foram encontrados documentos relevantes."
            
            # Envia contexto e query para o chat
            prompt = f"""Com base nestes documentos:

{context}

Por favor, responda √† pergunta do usu√°rio: {query}

Lembre-se:
1. Use apenas as informa√ß√µes dos documentos
2. Se n√£o houver informa√ß√£o suficiente, diga isso
3. Seja amig√°vel e conversacional
4. Use markdown para formatar a resposta"""
            
            # Tenta gerar resposta
            try:
                response = self.chat.send_message(prompt, stream=False)
                if response and hasattr(response, 'text'):
                    return response.text
                else:
                    return "Desculpe, n√£o consegui gerar uma resposta adequada."
            except Exception as e:
                console.print(f"\n[red]Erro ao gerar resposta: {str(e)}[/red]")
                return "Desculpe, ocorreu um erro ao gerar a resposta."
            
        except Exception as e:
            console.print(f"\n[red]Erro ao processar com Gemini: {str(e)}[/red]")
            return "Desculpe, ocorreu um erro ao processar sua pergunta."

class ChatHistory:
    """Gerencia o hist√≥rico da conversa."""
    
    def __init__(self, max_history: int = 5):
        self.messages: List[Dict[str, str]] = []
        self.max_history = max_history
        
    def add_message(self, role: str, content: str) -> None:
        """Adiciona mensagem ao hist√≥rico."""
        self.messages.append({"role": role, "content": content})
        if len(self.messages) > self.max_history:
            self.messages.pop(0)
            
    def get_context(self) -> str:
        """Retorna contexto da conversa para a pr√≥xima query."""
        context = []
        for msg in self.messages:
            prefix = "Usu√°rio" if msg["role"] == "user" else "Assistente"
            context.append(f"{prefix}: {msg['content']}")
        return "\n".join(context)
    
    def clear(self) -> None:
        """Limpa o hist√≥rico."""
        self.messages.clear()

@contextmanager
def ChatSpinner():
    """Context manager para mostrar spinner durante processamento."""
    with console.status("[bold green]Processando...", spinner="dots") as status:
        try:
            yield status
        finally:
            pass

def search_documents(query: str, context: str = "") -> Optional[Dict]:
    """Realiza busca sem√¢ntica via API.
    
    Args:
        query: Pergunta do usu√°rio
        context: Contexto da conversa
        
    Returns:
        Resultados da busca ou None se houver erro
    """
    try:
        # Constr√≥i endpoint de busca
        search_endpoint = get_api_url("search")
        
        # Prepara query com contexto
        full_query = f"{context}\nNova pergunta: {query}" if context else query
        
        # Faz requisi√ß√£o para a API
        response = requests.post(
            search_endpoint,
            json={"query": full_query},
            headers={"Content-Type": "application/json"}
        )
        
        # Verifica se a requisi√ß√£o foi bem sucedida
        response.raise_for_status()
        
        # Processa resultado
        try:
            data = response.json()
            
            # Verifica formato e ajusta se necess√°rio
            if isinstance(data, dict):
                if "results" in data:
                    # Formato esperado
                    return data
                else:
                    # Encapsula em results se necess√°rio
                    return {"results": data}
            else:
                console.print("\n[yellow]Aviso: Formato de resposta inesperado[/yellow]")
                return None
                
        except json.JSONDecodeError:
            console.print("\n[red]Erro ao decodificar resposta da API[/red]")
            return None
        
    except requests.exceptions.RequestException as e:
        console.print(f"\n[red]Erro ao conectar com a API: {str(e)}[/red]")
        console.print(f"\n[yellow]Tentando conectar em: {search_endpoint}[/yellow]")
        return None
    except Exception as e:
        console.print(f"\n[red]Erro inesperado: {str(e)}[/red]")
        return None

def format_response(response: str, docs: List[Dict]) -> None:
    """Formata e exibe a resposta.
    
    Args:
        response: Resposta processada
        docs: Lista de documentos relevantes
    """
    # Exibe resposta principal
    console.print("\n[bold]Resposta:[/bold]")
    console.print(Markdown(response))
    
    # Exibe documentos relevantes
    if docs:
        console.print(f"\n[bold]Documentos relevantes ({len(docs)} encontrados):[/bold]")
        
        # Cria tabela
        table = Table(show_header=True, header_style="bold")
        table.add_column("ID", style="dim")
        table.add_column("T√≠tulo")
        table.add_column("Relev√¢ncia", justify="right")
        
        # Adiciona resultados
        for doc in docs:
            similarity = doc.get("similarity", 0)
            table.add_row(
                str(doc.get("id", ""))[:10],
                doc.get("titulo", ""),
                f"{similarity*100:.0f}%"
            )
            
        console.print(table)

def main() -> None:
    """Fun√ß√£o principal."""
    try:
        # Inicializa chat e hist√≥rico
        chat = GeminiChat()
        history = ChatHistory()
        
        console.print("\n[bold]ü§ñ Assistente de Busca Sem√¢ntica[/bold]")
        console.print("Digite 'sair' para encerrar ou 'limpar' para reiniciar a conversa.")
        
        while True:
            # Obt√©m query do usu√°rio
            query = Prompt.ask("\n[bold]Voc√™[/bold]")
            
            # Verifica comandos especiais
            if query.lower() == "sair":
                console.print("\n[bold]üëã At√© logo![/bold]")
                break
            elif query.lower() == "limpar":
                history.clear()
                chat = GeminiChat()
                console.print("\n[bold]üîÑ Conversa reiniciada![/bold]")
                continue
            
            # Adiciona query ao hist√≥rico
            history.add_message("user", query)
            
            with ChatSpinner():
                # Processa query inicial
                initial_response = chat.process_initial_response(query)
                
                # Verifica se deve realizar busca
                if chat.should_search(initial_response):
                    # Remove tag [BUSCAR] da resposta
                    search_msg = initial_response.replace("[BUSCAR]", "").strip()
                    if search_msg:
                        console.print(f"\n[bold]ü§ñ Assistente:[/bold] {search_msg}")
                    
                    # Realiza busca
                    results = search_documents(query, history.get_context())
                    
                    if results:
                        # Processa documentos encontrados
                        docs = results.get("results", [])
                        response = chat.process_search_response(query, docs)
                        
                        # Formata e exibe resposta
                        format_response(response, docs)
                        
                        # Adiciona resposta ao hist√≥rico
                        history.add_message("assistant", response)
                    else:
                        console.print("\n[red]‚ùå N√£o foi poss√≠vel realizar a busca[/red]")
                else:
                    # Exibe resposta direta
                    console.print(f"\n[bold]ü§ñ Assistente:[/bold] {initial_response}")
                    
                    # Adiciona resposta ao hist√≥rico
                    history.add_message("assistant", initial_response)
                
    except KeyboardInterrupt:
        console.print("\n\n[bold]üëã At√© logo![/bold]")
    except Exception as e:
        console.print(f"\n[red]Erro inesperado: {str(e)}[/red]")

if __name__ == "__main__":
    main() 