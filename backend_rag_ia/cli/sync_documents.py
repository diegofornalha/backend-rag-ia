import hashlib
import json
import os

from dotenv import load_dotenv
from rich import print
from rich.console import Console
from rich.table import Table
from supabase import Client, create_client

# Carrega vari√°veis de ambiente
load_dotenv()

console = Console()

# Inicializa cliente Supabase com valores padr√£o caso n√£o encontre no .env
url: str = os.getenv("SUPABASE_URL", "https://xxxxxxxxxxxxxxxxxxxxxx.supabase.co")
key: str = os.getenv(
    "SUPABASE_KEY",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
)
supabase: Client = create_client(url, key)


def calculate_content_hash(content: str) -> str:
    """Calcula hash do conte√∫do normalizado."""
    normalized = json.dumps(content, sort_keys=True)
    return hashlib.sha256(normalized.encode()).hexdigest()


def get_all_documents():
    """Recupera todos os documentos do Supabase."""
    response = supabase.table("documents").select("*").execute()
    return response.data


def find_duplicates(documents):
    """Encontra documentos duplicados baseado no conte√∫do."""
    content_map = {}
    duplicates = []

    for doc in documents:
        content_hash = calculate_content_hash(doc["content"])
        if content_hash in content_map:
            duplicates.append({"original": content_map[content_hash], "duplicate": doc})
        else:
            content_map[content_hash] = doc

    return duplicates


def remove_duplicate(duplicate_info):
    """Remove o documento duplicado e mant√©m o original."""
    duplicate_id = duplicate_info["duplicate"]["id"]
    try:
        # Remove primeiro da tabela de embeddings
        supabase.table("embeddings").delete().eq("document_id", duplicate_id).execute()
        # Remove o documento
        supabase.table("documents").delete().eq("id", duplicate_id).execute()
        return True
    except Exception as e:
        print(f"‚ùå Erro ao remover duplicata {duplicate_id}: {e!s}")
        return False


def main():
    console.print("\nüîÑ Iniciando sincroniza√ß√£o de documentos...\n")

    # Recupera todos os documentos
    documents = get_all_documents()
    console.print(f"üìä Total de documentos encontrados: {len(documents)}")

    # Encontra duplicatas
    duplicates = find_duplicates(documents)
    console.print(f"\nüîç Encontradas {len(duplicates)} duplicatas")

    if not duplicates:
        console.print("\n‚úÖ N√£o h√° duplicatas para remover!")
        return

    # Mostra tabela de duplicatas
    table = Table(title="Documentos Duplicados")
    table.add_column("Original ID")
    table.add_column("Duplicata ID")
    table.add_column("Conte√∫do")

    for dup in duplicates:
        table.add_row(
            str(dup["original"]["id"]),
            str(dup["duplicate"]["id"]),
            dup["original"]["content"][:50] + "...",
        )

    console.print(table)

    # Remove duplicatas
    console.print("\nüßπ Removendo duplicatas...")
    removed = 0
    for dup in duplicates:
        if remove_duplicate(dup):
            removed += 1
            console.print(f"‚úÖ Removida duplicata {dup['duplicate']['id']}")

    console.print("\n‚ú® Sincroniza√ß√£o conclu√≠da!")
    console.print("üìä Estat√≠sticas finais:")
    console.print(f"   - Total de documentos originais: {len(documents)}")
    console.print(f"   - Duplicatas encontradas: {len(duplicates)}")
    console.print(f"   - Duplicatas removidas: {removed}")
    console.print(f"   - Total ap√≥s limpeza: {len(documents) - removed}")


if __name__ == "__main__":
    main()
